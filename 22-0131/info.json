{
    "abstract": "Learning problems commonly exhibit an interesting feedback mechanism wherein the population data reacts to competing decision makers' actions. This paper formulates a new game theoretic framework for this phenomenon, called multi-player performative prediction. We focus on two distinct solution concepts, namely (i) performatively stable equilibria and (ii) Nash equilibria of the game. The latter equilibria are arguably more informative, but are generally computationally difficult to find since they are solutions of non-monotone games. We show that under mild assumptions, the performatively stable equilibria can be found efficiently by a variety of algorithms, including repeated retraining and the repeated (stochastic) gradient method. We then establish transparent sufficient conditions for strong monotonicity of the game and use them to develop algorithms for finding Nash equilibria. We investigate derivative free methods and adaptive gradient algorithms wherein each player alternates between learning a parametric description of their distribution and gradient steps on the empirical risk. Synthetic and semi-synthetic numerical experiments illustrate the results.",
    "authors": [
        "Adhyyan Narang",
        "Evan Faulkner",
        "Dmitriy Drusvyatskiy",
        "Maryam Fazel",
        "Lillian J. Ratliff"
    ],
    "emails": [
        "adhyyan@uw.edu",
        "evanjf5@uw.edu",
        "ddrusv@uw.edu",
        "mfazel@uw.edu",
        "ratliffl@uw.edu"
    ],
    "extra_links": [
        [
            "code",
            "https://github.com/ratlifflj/performativepredictiongames"
        ]
    ],
    "id": "22-0131",
    "issue": 202,
    "pages": [
        1,
        56
    ],
    "title": "Multiplayer Performative Prediction: Learning in Decision-Dependent Games",
    "volume": 24,
    "year": 2023
}