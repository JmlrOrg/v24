{
    "abstract": "Scaling up training datasets and model parameters have benefited neural network-based language models, but also present challenges like distributed compute, input data bottlenecks and reproducibility of results. We introduce two simple and scalable software libraries that simplify these issues: t5x enables training large language models at scale, while seqio enables reproducible input and evaluation pipelines. These open-source libraries have been used to train models with hundreds of billions of parameters on multi-terabyte datasets. Configurations and instructions for T5-like and GPT-like models are also provided. The libraries can be found at https://github.com/google-research/t5x and https://github.com/google/seqio.",
    "authors": [
        "Adam Roberts",
        "Hyung Won Chung",
        "Gaurav Mishra",
        "Anselm Levskaya",
        "James Bradbury",
        "Daniel Andor",
        "Sharan Narang",
        "Brian Lester",
        "Colin Gaffney",
        "Afroz Mohiuddin",
        "Curtis Hawthorne",
        "Aitor Lewkowycz",
        "Alex Salcianu",
        "Marc van Zee",
        "Jacob Austin",
        "Sebastian Goodman",
        "Livio Baldini Soares",
        "Haitang Hu",
        "Sasha Tsvyashchenko",
        "Aakanksha Chowdhery",
        "Jasmijn Bastings",
        "Jannis Bulian",
        "Xavier Garcia",
        "Jianmo Ni",
        "Andrew Chen",
        "Kathleen Kenealy",
        "Kehang Han",
        "Michelle Casbon",
        "Jonathan H. Clark",
        "Stephan Lee",
        "Dan Garrette",
        "James Lee-Thorp",
        "Colin Raffel",
        "Noam Shazeer",
        "Marvin Ritter",
        "Maarten Bosma",
        "Alexandre Passos",
        "Jeremy Maitin-Shepard",
        "Noah Fiedel",
        "Mark Omernick",
        "Brennan Saeta",
        "Ryan Sepassi",
        "Alexander Spiridonov",
        "Joshua Newlan",
        "Andrea Gesmundo"
    ],
    "emails": [
        "adarob@google.com",
        "h.w.chung27@gmail.com",
        "mishragaurav@google.com",
        "levskaya@gmail.com",
        "jekbradbury@google.com",
        "danielandor@google.com",
        "sharan.narang@gmail.com",
        "blester125@gmail.com",
        "cpgaffney@google.com",
        "afroz.mohiuddin@gmail.com",
        "cghawthorne@gmail.com",
        "lewkow@gmail.com",
        "salcianu@google.com",
        "marcvanzee@google.com",
        "jaaustin@google.com",
        "sebastian.goodman@gmail.com",
        "liviobs@google.com",
        "nero.hu2011@gmail.com",
        "ndl@endl.ch",
        "chowdhery@google.com",
        "bastings@google.com",
        "jannis@bulian.org",
        "xgarcia@google.com",
        "nijianmo@gmail.com",
        "chenandrew@google.com",
        "kkenealy@google.com",
        "kehanghan@gmail.com",
        "michellecasbon@gmail.com",
        "jhclark@google.com",
        "stephanwlee@gmail.com",
        "dhgarrette@google.com",
        "jamesleethorp@google.com",
        "craffel@gmail.com",
        "noam@google.com",
        "marvin.ritter@gmail.com",
        "maarten@bosma.de",
        "alexandre.tp@gmail.com",
        "jeremy@jeremyms.com",
        "nfiedel@gmail.com",
        "momernick@google.com",
        "saeta@google.com",
        "rsepassi@gmail.com",
        "spiridonov@google.com",
        "joshuanewlan@gmail.com",
        "gesmundo@gmail.com"
    ],
    "extra_links": [
        [
            "code",
            "https://github.com/google-research/t5x"
        ]
    ],
    "id": "23-0795",
    "issue": 377,
    "pages": [
        1,
        8
    ],
    "special_issue": "MLOSS",
    "title": "Scaling Up Models and Data with t5x and seqio",
    "volume": 24,
    "year": 2023
}