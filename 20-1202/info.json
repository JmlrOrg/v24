{
    "abstract": "This paper presents an inverse reinforcement learning (IRL) framework for Bayesian stopping time problems. By observing the actions of a Bayesian decision maker, we provide a necessary and sufficient condition to identify if these actions are consistent with optimizing a cost function. In a Bayesian (partially observed) setting, the inverse learner can at best identify optimality wrt the observed strategies. Our IRL algorithm identifies optimality and then constructs set-valued estimates of the cost function. To achieve this IRL objective, we use novel ideas from Bayesian revealed preferences stemming from microeconomics. We illustrate the proposed IRL scheme using two important examples of stopping time problems, namely, sequential hypothesis testing and Bayesian search. As a real-world example, we illustrate using a YouTube dataset comprising metadata from 190000 videos how the proposed IRL method predicts user engagement in online multimedia platforms with high accuracy. Finally, for finite datasets, we propose an IRL detection algorithm and give finite sample bounds on its error probabilities.",
    "authors": [
        "Kunal Pattanayak",
        "Vikram Krishnamurthy"
    ],
    "emails": [
        "kp487@cornell.edu",
        "vikramk@cornell.edu"
    ],
    "id": "20-1202",
    "issue": 52,
    "pages": [
        1,
        64
    ],
    "title": "Necessary and Sufficient Conditions for Inverse Reinforcement Learning of Bayesian Stopping Time Problems",
    "volume": 24,
    "year": 2023
}